{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#load enivronment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "gorq_key= os.getenv(\"API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The capital city of Texas is Austin.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 42, 'total_tokens': 51, 'completion_time': 0.012, 'prompt_time': 0.002312491, 'queue_time': 0.195234993, 'total_time': 0.014312491}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_19ca34f5ed', 'finish_reason': 'stop', 'logprobs': None} id='run-8dcb7772-1a01-4ed7-b66a-1308fb045f1d-0' usage_metadata={'input_tokens': 42, 'output_tokens': 9, 'total_tokens': 51}\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    temperature=0,\n",
    "    groq_api_key=gorq_key\n",
    "\n",
    ")\n",
    "response=llm.invoke(\"what is the capital city of Texas\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#web scraping the job details\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://careers.nike.com/lead-data-scientist/job/R-56462\")\n",
    "job_posting_extracted= loader.load().pop().page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"Lead Data Scientist\",\n",
      "  \"experience\": \"At least 3–5-years relevant working experience\",\n",
      "  \"skills\": [\n",
      "    \"Strong proficiency in programming languages Python and SQL\",\n",
      "    \"Solid understanding of statistical analysis, data mining, and predictive modeling techniques\",\n",
      "    \"Strong problem-solving skills and the ability to work independently and as part of a team\",\n",
      "    \"Excellent communication and presentation skills\"\n",
      "  ],\n",
      "  \"description\": \"Develop, implement, deploy and maintain predictive models. Analyse large, complex datasets to extract insights and identify trends. Collaborate with stakeholders to understand business needs and provide data-driven solutions. Communicate findings and recommendations to non-technical stakeholders through visualizations and reports. Stay up to date with the latest industry trends and technologies in data science and machine/deep learning. Ensure data quality and integrity throughout the data lifecycle.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"  \n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the deatils about the job and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description' and if you have required and goot_to_have the dont mention them seperately as key instead make it as a list.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm\n",
    "job_description_scraped = chain_extract.invoke(input={'page_data': job_posting_extracted})\n",
    "print(job_description_scraped.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(job_description_scraped.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Lead Data Scientist',\n",
       " 'experience': 'At least 3–5-years relevant working experience',\n",
       " 'skills': ['Strong proficiency in programming languages Python and SQL',\n",
       "  'Solid understanding of statistical analysis, data mining, and predictive modeling techniques',\n",
       "  'Strong problem-solving skills and the ability to work independently and as part of a team',\n",
       "  'Excellent communication and presentation skills'],\n",
       " 'description': 'Develop, implement, deploy and maintain predictive models. Analyse large, complex datasets to extract insights and identify trends. Collaborate with stakeholders to understand business needs and provide data-driven solutions. Communicate findings and recommendations to non-technical stakeholders through visualizations and reports. Stay up to date with the latest industry trends and technologies in data science and machine/deep learning. Ensure data quality and integrity throughout the data lifecycle.'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "job_description= json_parser.parse(job_description_scraped.content)\n",
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the content from the resume\n",
    "from docx import Document\n",
    "import os\n",
    "\n",
    "resume_doc= Document(os.path.join(os.getcwd(),  \"Data-Scientist-Resume-Sample.docx\"))\n",
    "resume_context= [(para.text).strip() for para in resume_doc.paragraphs]\n",
    "# print(resume_context)\n",
    "resume_context_list= [content for content in resume_context if content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 8\n",
      "\n",
      "Total token_splits: 41\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import(\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter\n",
    ")\n",
    "\n",
    "character_splitter= RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\",\".\"], chunk_size=500, chunk_overlap=50\n",
    ")\n",
    "\n",
    "character_split_text= character_splitter.split_text(\"\\n\\n\".join(resume_context_list))\n",
    "\n",
    "# print(\"chunk split\",character_split_text)\n",
    "# # print(word_wrap(character_split_text[10]))\n",
    "print(f\"\\nTotal chunks: {len(character_split_text)}\")\n",
    "\n",
    "\n",
    "token_splitter= SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap=5, tokens_per_chunk=20\n",
    ")\n",
    "token_split_texts=[]\n",
    "for text in character_split_text:\n",
    "    token_split_texts+= token_splitter.split_text(text)\n",
    "print(f\"\\nTotal token_splits: {(len(token_split_texts))}\")\n",
    "# print(\"token split\")\n",
    "# # print(token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection: resume-context\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions \n",
    "\n",
    "embedding_function= embedding_functions.SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "#instaitating chromadb client\n",
    "chroma_client= chromadb.PersistentClient()\n",
    "\n",
    "collection_name = \"resume-context\" \n",
    "\n",
    "# Check if it exists\n",
    "if collection_name in chroma_client.list_collections():\n",
    "    chroma_client.delete_collection(name=collection_name)\n",
    "    print(f\"Deleted existing collection: {collection_name}\")\n",
    "\n",
    "# Create a new one\n",
    "chroma_collection = chroma_client.create_collection(\n",
    "    name=collection_name,\n",
    "    embedding_function=embedding_function\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#extract the embeddings of the token_split_texts\n",
    "ids=[str(i) for i in range(len(token_split_texts))]\n",
    "chroma_collection.add( ids= ids, documents= token_split_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skills : probability & statistics, linear algebra, machine learning, computer science, artificial neural networks tools and',\n",
       " 'ai ) simultaneously trying to synergies my skill sets of technological expertise and leadership qualities. i also',\n",
       " 'leadership qualities. i also intend to devote most of my time in doing research and mark my significant contribution',\n",
       " 'others : my core area of expertise in analysis and building predictive models. i have developed random forest',\n",
       " 'card model. i am also fond of writing research papers. i have written a few papers related to']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query=\"what is are the skills that you have?\"\n",
    "# results= chroma_collection.query(query_texts=[query], n_results=5)\n",
    "# retrived_documents= results[\"documents\"][0]\n",
    "# retrived_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john doe data scientist summary career objective : i intend to explore a variety of areas in machine learning () - 7. 43 cpi2. bachelors – b. e. ( computer engineering - gujarat'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_name_retrived= chroma_collection.query(query_texts=\"what is the name of the person in the resume?\", n_results=2)\n",
    "candidated_name=\"\".join(candidate_name_retrived[\"documents\"][0])\n",
    "candidated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', hadoop, python, tableau past experience : 1. worked in an ai ( artificial intelligencemodeling, text analysis, java, ruby on rails, mysql, hadoop, pythonskills : probability & statistics, linear algebra, machine learning, computer science, artificial neural networks tools and, and analytics. java developer at quick developments, sqlyog, apache tomcat education nirma university, ahmedabad, gujarat, india master of'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_skills_retrived= chroma_collection.query(query_texts=job_description['skills'], n_results=5)\n",
    "candidate_skills= \"\".join(candidate_skills_retrived[\"documents\"][0])\n",
    "candidate_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "    \"\"\"  \n",
    "    ### JOB DESCRIPTION:\n",
    "    {job_description}\n",
    "\n",
    "    ### CANDIDATE skills:\n",
    "    {candidate_skills}\n",
    "\n",
    "    ### Candidate Name:\n",
    "    {candidate_name}\n",
    "\n",
    "    ### INSTRUCTION:\n",
    "    Write a professional and short concise email to the hiring manager expressing interest in the above job. \n",
    "    start with the name and introduction of the candidate’s and highlight relevant skills and experience from the resume that align with the job description.\n",
    "    The tone should be enthusiastic, confident, and tailored to the job.\n",
    "\n",
    "    ### EMAIL (NO PREAMBLE):\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "email_for_hiring_manager = chain_email.invoke({\"job_description\": str(job_description), \"candidate_skills\" : candidate_skills, \"candidate_name\" : candidated_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Lead Data Scientist Position\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my strong interest in the Lead Data Scientist position at your esteemed organization. My name is John Doe, and I am a seasoned data scientist with a passion for developing and implementing predictive models, analyzing complex datasets, and driving business growth through data-driven insights.\n",
      "\n",
      "With over 5 years of experience in the field, I possess a strong proficiency in programming languages such as Python and SQL, as well as expertise in statistical analysis, data mining, and predictive modeling techniques. My experience with Hadoop, Java, and Ruby on Rails has also equipped me with the ability to work with large datasets and develop scalable solutions.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to collaborate with stakeholders, communicate complex findings to non-technical audiences, and stay up-to-date with the latest industry trends and technologies in data science and machine learning. My experience with Tableau has also honed my skills in data visualization and communication.\n",
      "\n",
      "I am confident that my skills, experience, and passion for data science make me an ideal candidate for this position. I would welcome the opportunity to discuss my application and how I can contribute to your organization's success.\n",
      "\n",
      "Thank you for considering my application. I look forward to the opportunity to discuss this further.\n",
      "\n",
      "Best regards,\n",
      "John Doe\n"
     ]
    }
   ],
   "source": [
    "print(email_for_hiring_manager.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
